{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 3. Pandas, метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: \n",
    "\n",
    "Student ID: \n",
    "\n",
    "Email: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на вопросы о данных по авиарейсам в США.\n",
    "\n",
    "Данные: http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n",
    "(обратите внимание, что распаковывать этот файл не обязательно — функция `pandas.read_csv` умеет читать из архивов автоматически)\n",
    "\n",
    "Описание: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "1. Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)\n",
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом.\n",
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?\n",
    "4. Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?\n",
    "5. Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?\n",
    "6. Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7009728.0</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>6.873482e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>6.858079e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>7009728</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.858079e+06</td>\n",
       "      <td>6.872670e+06</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>137434</td>\n",
       "      <td>7.009728e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "      <td>1.524735e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1201754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>6.375130e+00</td>\n",
       "      <td>1.572801e+01</td>\n",
       "      <td>3.924182e+00</td>\n",
       "      <td>1.333830e+03</td>\n",
       "      <td>1.326086e+03</td>\n",
       "      <td>1.481258e+03</td>\n",
       "      <td>1.494801e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.224200e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.860852e+00</td>\n",
       "      <td>1.645305e+01</td>\n",
       "      <td>1.960618e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.463006e-03</td>\n",
       "      <td>1.577206e+01</td>\n",
       "      <td>3.039031e+00</td>\n",
       "      <td>1.716462e+01</td>\n",
       "      <td>7.497434e-02</td>\n",
       "      <td>2.077098e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.406737e+00</td>\n",
       "      <td>8.797068e+00</td>\n",
       "      <td>1.988259e+00</td>\n",
       "      <td>4.780689e+02</td>\n",
       "      <td>4.642509e+02</td>\n",
       "      <td>5.052251e+02</td>\n",
       "      <td>4.826728e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.961716e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.933649e+00</td>\n",
       "      <td>1.133280e+01</td>\n",
       "      <td>1.386426e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.956753e-02</td>\n",
       "      <td>4.009912e+01</td>\n",
       "      <td>1.950287e+01</td>\n",
       "      <td>3.189495e+01</td>\n",
       "      <td>1.837940e+00</td>\n",
       "      <td>3.925964e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.280000e+02</td>\n",
       "      <td>9.250000e+02</td>\n",
       "      <td>1.107000e+03</td>\n",
       "      <td>1.115000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.220000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.325000e+03</td>\n",
       "      <td>1.320000e+03</td>\n",
       "      <td>1.512000e+03</td>\n",
       "      <td>1.517000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.571000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.728000e+03</td>\n",
       "      <td>1.715000e+03</td>\n",
       "      <td>1.909000e+03</td>\n",
       "      <td>1.907000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.518000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.743000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.080000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.436000e+03</td>\n",
       "      <td>1.352000e+03</td>\n",
       "      <td>1.357000e+03</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>1.316000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Year         Month    DayofMonth     DayOfWeek       DepTime  \\\n",
       "count   7009728.0  7.009728e+06  7.009728e+06  7.009728e+06  6.873482e+06   \n",
       "unique        NaN           NaN           NaN           NaN           NaN   \n",
       "top           NaN           NaN           NaN           NaN           NaN   \n",
       "freq          NaN           NaN           NaN           NaN           NaN   \n",
       "mean       2008.0  6.375130e+00  1.572801e+01  3.924182e+00  1.333830e+03   \n",
       "std           0.0  3.406737e+00  8.797068e+00  1.988259e+00  4.780689e+02   \n",
       "min        2008.0  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "25%        2008.0  3.000000e+00  8.000000e+00  2.000000e+00  9.280000e+02   \n",
       "50%        2008.0  6.000000e+00  1.600000e+01  4.000000e+00  1.325000e+03   \n",
       "75%        2008.0  9.000000e+00  2.300000e+01  6.000000e+00  1.728000e+03   \n",
       "max        2008.0  1.200000e+01  3.100000e+01  7.000000e+00  2.400000e+03   \n",
       "\n",
       "          CRSDepTime       ArrTime    CRSArrTime UniqueCarrier     FlightNum  \\\n",
       "count   7.009728e+06  6.858079e+06  7.009728e+06       7009728  7.009728e+06   \n",
       "unique           NaN           NaN           NaN            20           NaN   \n",
       "top              NaN           NaN           NaN            WN           NaN   \n",
       "freq             NaN           NaN           NaN       1201754           NaN   \n",
       "mean    1.326086e+03  1.481258e+03  1.494801e+03           NaN  2.224200e+03   \n",
       "std     4.642509e+02  5.052251e+02  4.826728e+02           NaN  1.961716e+03   \n",
       "min     0.000000e+00  1.000000e+00  0.000000e+00           NaN  1.000000e+00   \n",
       "25%     9.250000e+02  1.107000e+03  1.115000e+03           NaN  6.220000e+02   \n",
       "50%     1.320000e+03  1.512000e+03  1.517000e+03           NaN  1.571000e+03   \n",
       "75%     1.715000e+03  1.909000e+03  1.907000e+03           NaN  3.518000e+03   \n",
       "max     2.359000e+03  2.400000e+03  2.400000e+03           NaN  9.743000e+03   \n",
       "\n",
       "              ...                TaxiIn       TaxiOut     Cancelled  \\\n",
       "count         ...          6.858079e+06  6.872670e+06  7.009728e+06   \n",
       "unique        ...                   NaN           NaN           NaN   \n",
       "top           ...                   NaN           NaN           NaN   \n",
       "freq          ...                   NaN           NaN           NaN   \n",
       "mean          ...          6.860852e+00  1.645305e+01  1.960618e-02   \n",
       "std           ...          4.933649e+00  1.133280e+01  1.386426e-01   \n",
       "min           ...          0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%           ...          4.000000e+00  1.000000e+01  0.000000e+00   \n",
       "50%           ...          6.000000e+00  1.400000e+01  0.000000e+00   \n",
       "75%           ...          8.000000e+00  1.900000e+01  0.000000e+00   \n",
       "max           ...          3.080000e+02  4.290000e+02  1.000000e+00   \n",
       "\n",
       "        CancellationCode      Diverted  CarrierDelay  WeatherDelay  \\\n",
       "count             137434  7.009728e+06  1.524735e+06  1.524735e+06   \n",
       "unique                 4           NaN           NaN           NaN   \n",
       "top                    B           NaN           NaN           NaN   \n",
       "freq               54904           NaN           NaN           NaN   \n",
       "mean                 NaN  2.463006e-03  1.577206e+01  3.039031e+00   \n",
       "std                  NaN  4.956753e-02  4.009912e+01  1.950287e+01   \n",
       "min                  NaN  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%                  NaN  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%                  NaN  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%                  NaN  0.000000e+00  1.600000e+01  0.000000e+00   \n",
       "max                  NaN  1.000000e+00  2.436000e+03  1.352000e+03   \n",
       "\n",
       "            NASDelay  SecurityDelay  LateAircraftDelay  \n",
       "count   1.524735e+06   1.524735e+06       1.524735e+06  \n",
       "unique           NaN            NaN                NaN  \n",
       "top              NaN            NaN                NaN  \n",
       "freq             NaN            NaN                NaN  \n",
       "mean    1.716462e+01   7.497434e-02       2.077098e+01  \n",
       "std     3.189495e+01   1.837940e+00       3.925964e+01  \n",
       "min     0.000000e+00   0.000000e+00       0.000000e+00  \n",
       "25%     0.000000e+00   0.000000e+00       0.000000e+00  \n",
       "50%     6.000000e+00   0.000000e+00       0.000000e+00  \n",
       "75%     2.100000e+01   0.000000e+00       2.600000e+01  \n",
       "max     1.357000e+03   3.920000e+02       1.316000e+03  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"2008.csv.bz2\")\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B    54904\n",
      "Name: CancellationCode, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#first question\n",
    "print(data['CancellationCode'].value_counts()[:1])\n",
    "#B is weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance 726.3870294253928\n",
      "Minimum distance 11\n",
      "Maximum distance 4962\n"
     ]
    }
   ],
   "source": [
    "#second question\n",
    "print(\"Average distance\", data['Distance'].mean())\n",
    "print(\"Minimum distance\", data['Distance'].min())\n",
    "print(\"Maximum distance\", data['Distance'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2547298    2008\n",
      "4392215    2008\n",
      "Name: Year, dtype: int64 2547298    5\n",
      "4392215    8\n",
      "Name: Month, dtype: int64 2547298    15\n",
      "4392215    10\n",
      "Name: DayofMonth, dtype: int64\n",
      "151771     834\n",
      "152430     834\n",
      "153088     834\n",
      "153545     834\n",
      "154096     834\n",
      "154750     834\n",
      "155308     834\n",
      "155962     834\n",
      "156627     834\n",
      "157287     834\n",
      "157747     834\n",
      "158301     834\n",
      "158958     834\n",
      "159514     834\n",
      "160169     834\n",
      "160833     834\n",
      "161492     834\n",
      "161950     834\n",
      "162493     834\n",
      "163151     834\n",
      "163707     834\n",
      "164361     834\n",
      "165027     834\n",
      "165688     834\n",
      "166150     834\n",
      "166704     834\n",
      "167361     834\n",
      "167917     834\n",
      "168567     834\n",
      "453560     834\n",
      "          ... \n",
      "6776729    903\n",
      "6776730    903\n",
      "6776731    903\n",
      "6776732    903\n",
      "6776733    903\n",
      "6776734    903\n",
      "6776735    903\n",
      "6776736    903\n",
      "6776737    903\n",
      "6776738    903\n",
      "6776739    903\n",
      "6776740    903\n",
      "6776741    903\n",
      "6776742    903\n",
      "6776743    903\n",
      "6776744    903\n",
      "6776745    903\n",
      "6776746    903\n",
      "6776747    903\n",
      "6776748    903\n",
      "6776749    903\n",
      "6776750    903\n",
      "6776751    903\n",
      "6776752    903\n",
      "6776753    903\n",
      "6776754    903\n",
      "6776755    903\n",
      "6776756    903\n",
      "6776757    903\n",
      "6776758    903\n",
      "Name: Distance, Length: 225, dtype: int64\n",
      "151629     544\n",
      "152291     544\n",
      "152949     544\n",
      "153419     544\n",
      "153963     544\n",
      "154611     544\n",
      "155185     544\n",
      "155823     544\n",
      "156485     544\n",
      "157148     544\n",
      "157622     544\n",
      "158169     544\n",
      "158819     544\n",
      "159392     544\n",
      "160029     544\n",
      "160692     544\n",
      "161355     544\n",
      "161828     544\n",
      "162361     544\n",
      "163012     544\n",
      "163585     544\n",
      "164222     544\n",
      "164885     544\n",
      "165549     544\n",
      "166024     544\n",
      "166572     544\n",
      "167222     544\n",
      "167795     544\n",
      "168432     544\n",
      "169083     544\n",
      "          ... \n",
      "6635221    329\n",
      "6635222    329\n",
      "6635223    329\n",
      "6635224    329\n",
      "6635225    329\n",
      "6635226    329\n",
      "6635227    329\n",
      "6635228    329\n",
      "6635229    329\n",
      "6635230    329\n",
      "6635231    329\n",
      "6635232    329\n",
      "6771546    669\n",
      "6771547    134\n",
      "6771548    134\n",
      "6771549    134\n",
      "6771550    134\n",
      "6771551    134\n",
      "6771552    134\n",
      "6771553    134\n",
      "6771554    134\n",
      "6771555    134\n",
      "6771556    134\n",
      "6771557    134\n",
      "6771558    134\n",
      "6771559    669\n",
      "6771560    508\n",
      "6771561    508\n",
      "6771562    508\n",
      "6771563    508\n",
      "Name: Distance, Length: 826, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#third question\n",
    "f = data[data['Distance'] == data['Distance'].min()]\n",
    "print(f['Year'], f['Month'], f['DayofMonth'])\n",
    "for ind in f['FlightNum']:\n",
    "    print(data[data['FlightNum'] == ind]['Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL    414513\n",
      "Name: Origin, dtype: int64\n",
      "Hartsfield-Jackson Atlanta International Airport\n"
     ]
    }
   ],
   "source": [
    "#fourth question\n",
    "print(data['Origin'].value_counts()[:1])\n",
    "print('Hartsfield-Jackson Atlanta International Airport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "ABE    1275.191819\n",
      "ABI    1086.024847\n",
      "ABQ    1485.039293\n",
      "ABY    1264.013915\n",
      "ACK    1380.863962\n",
      "ACT    1346.037520\n",
      "ACV    1340.364884\n",
      "ACY    1307.508929\n",
      "ADK    2141.663043\n",
      "ADQ    1339.030166\n",
      "AEX    1243.754331\n",
      "AGS    1277.597540\n",
      "AKN    1739.553571\n",
      "ALB    1372.557040\n",
      "ALO     794.567164\n",
      "AMA    1361.533515\n",
      "ANC    1230.692827\n",
      "ASE    1380.380112\n",
      "ATL    1538.640892\n",
      "ATW    1320.374932\n",
      "AUS    1429.958819\n",
      "AVL    1300.312354\n",
      "AVP    1317.197720\n",
      "AZO    1256.796840\n",
      "BDL    1379.090511\n",
      "BET    1607.815293\n",
      "BFL    1306.524848\n",
      "BGM    1303.797143\n",
      "BGR    1373.504498\n",
      "BHM    1424.988602\n",
      "          ...     \n",
      "SPS    1402.234491\n",
      "SRQ    1485.504576\n",
      "STL    1488.664610\n",
      "STT    1727.368765\n",
      "STX    1945.861502\n",
      "SUN    1356.823857\n",
      "SUX    1438.864865\n",
      "SWF    1383.226816\n",
      "SYR    1334.538830\n",
      "TEX    1450.150327\n",
      "TLH    1333.159260\n",
      "TOL    1163.566714\n",
      "TPA    1490.027120\n",
      "TRI    1256.122141\n",
      "TUL    1347.662225\n",
      "TUP    1242.400000\n",
      "TUS    1395.074820\n",
      "TVC    1241.551210\n",
      "TWF    1366.456190\n",
      "TXK    1266.499581\n",
      "TYR    1269.875979\n",
      "TYS    1321.995839\n",
      "VLD    1247.942516\n",
      "VPS    1386.072951\n",
      "WRG    1426.700730\n",
      "WYS    1591.885932\n",
      "XNA    1327.303469\n",
      "YAK    1593.808239\n",
      "YKM    1068.210682\n",
      "YUM    1337.077798\n",
      "Name: ArrTime, Length: 303, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#fifth question\n",
    "group = data.groupby('Origin')\n",
    "print(group['ArrTime'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dba = group.filter(lambda x: len(x) >= 1000).groupby('Origin').DepDelay.agg(lambda x: (x > 0).sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "DAL    0.578642\n",
      "Name: DepDelay, dtype: float64 0.5786418928942293\n"
     ]
    }
   ],
   "source": [
    "print(dba.loc[dba == dba.max()], dba.max()) #Dallas airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: метрические методы и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все дальнейшие эксперименты предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре.\n",
    "\n",
    "Проще всего будет определить метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba). Можно реализовать метод k ближайших соседей и самостоятально — в этом случае учитите, что он должен возвращать оценку вероятности, то есть отношение объектов первого класса среди соседей к числу соседей).\n",
    "\n",
    "Постарайтесь уделить особое внимание эффективности кода — при реализации метрик \"в лоб\" вы можете столкнуться с очень большим временем выполнения.\n",
    "\n",
    "#### Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Мера качества — AUC-ROC.\n",
    "\n",
    "#### Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось получить?\n",
    "\n",
    "Для подбора можно использовать любые средства из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`successes` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанные по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $(f_i, f_j)$, $i < j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$ (желательно через какой-нибудь специальный символ во избежание коллизий). Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав такое число деревьев `n_estimators`, при котором ошибка выходит на асимптоту. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмите выборку с парными признаками, для которой счетчики посчитаны с фолдингом. Обучите на ней случайный лес, подобрав число деревьев. Какое качество на тестовой выборке он дает? Чем вы можете объяснить изменение результата по сравнению с предыдущим пунктом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями о задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь вставьте смешную картинку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь посоветуйте преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
